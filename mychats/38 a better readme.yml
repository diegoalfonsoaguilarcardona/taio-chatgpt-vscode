- role: system
  content: You are a helpfull assistant. Remember to diferenciate the codes with Triple backticks.
  selected: true
  collapsed: false
- role: user
  content: 'Note: reference to media/main.js was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to package-lock.json was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to package.json was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to src/chatGptViewProvider.ts was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to src/extension.ts was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to src/types.ts was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to tsconfig.json was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to vsc-extension-quickstart.md was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to webpack.config.js was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to yarn.lock was here.'
  selected: true
  collapsed: true
- role: user
  content: Create a README.md file for this project.  Include a section for the users, but also a section for the developers.  Also add all the sections that you consider a good README.md file should have.
  selected: true
  collapsed: false
- role: assistant
  content: |-
    Responses message output item:
    ```json
    {
      "id": "msg_027d0d02097739ec00692a34c4a98881a2a167fc27d58659b9",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "annotations": [],
          "logprobs": [],
          "text": "```markdown\n# DevMate AI Chat\n\nUse ChatGPT, GPT‑4, and compatible APIs right inside VS Code to enhance and automate your coding with AI‑powered assistance. DevMate provides a flexible provider/model selector, rich chat UI with streaming, token stats, file/content references, images, YAML import/export, and more.\n\n- Publisher: `diegoaac`\n- Extension ID: `diegoaac.devmate-ai-chat`\n- License: MIT\n\n---\n\n## Table of Contents\n\n- [Features](#features)\n- [Requirements](#requirements)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n  - [Providers (devmate.providers)](#providers-devmateproviders)\n  - [System Prompts (devmate.prompts)](#system-prompts-devmateprompts)\n  - [Behavior Settings](#behavior-settings)\n- [Usage](#usage)\n  - [The Chat View](#the-chat-view)\n  - [Commands](#commands)\n  - [Working with Files and Images](#working-with-files-and-images)\n  - [YAML Import/Export](#yaml-importexport)\n  - [Streaming, Reasoning, and Stats](#streaming-reasoning-and-stats)\n  - [Keyboard Shortcuts](#keyboard-shortcuts)\n- [Privacy & Security](#privacy--security)\n- [Troubleshooting](#troubleshooting)\n- [Known Limitations](#known-limitations)\n- [Roadmap](#roadmap)\n- [Contributing](#contributing)\n- [Development Guide](#development-guide)\n  - [Project Structure](#project-structure)\n  - [Build, Run, Test](#build-run-test)\n  - [Packaging & Publishing](#packaging--publishing)\n  - [Webview Messaging Protocol](#webview-messaging-protocol)\n  - [Providers & APIs](#providers--apis)\n- [Changelog](#changelog)\n- [License](#license)\n\n---\n\n## Features\n\n- Provider and Model selectors with per‑model API type:\n  - Chat Completions (e.g., `gpt-4o-mini`, compatible endpoints)\n  - Responses API (OpenAI v6+ Responses with tools and reasoning)\n- Streaming output with low-latency rendering\n  - Shows reasoning deltas in a distinct style while streaming (not persisted to history)\n- Token stats bar: total/used tokens and current model\n- Rich chat controls per message:\n  - Include/Exclude message from context (checkbox)\n  - Collapse/Expand with preview\n  - Edit message content inline\n  - “Move reference to end” toggle for file references\n- File workflows:\n  - Add file content (code blocks) to chat\n  - Add lightweight file reference (content expanded at send time)\n  - Add multiple references/images from selected path lists\n  - Clickable inline `code` that looks like a file path opens & adds it\n- Image support:\n  - Drag/paste images into the prompt input (as image parts)\n  - Add images from Explorer context menu\n- YAML import/export:\n  - Export the current chat as YAML\n  - Replace or append chat by selecting YAML in the editor\n- System Prompt selector (from configured prompts)\n- Click‑to‑paste any code block into the editor (configurable)\n\n---\n\n## Requirements\n\n- VS Code ≥ 1.73.0\n- A compatible AI provider account and API key (e.g., OpenAI)\n- NodeJS environment for development (see [Development Guide](#development-guide))\n\n---\n\n## Installation\n\n1. Open VS Code.\n2. Install the extension (packaged `vsix` or from Marketplace when published).\n3. Open Command Palette → “DevMate AI Chat: Ask DevMate AI Chat” (or open the “DevMate AI Chat” view from the Activity Bar).\n\n---\n\n## Quick Start\n\n1. Open Settings (Ctrl/Cmd + ,) and search for “DevMate AI Chat”.\n2. Configure at least one provider in `devmate.providers`. See example below.\n3. Open the “DevMate AI Chat” view from the Activity Bar.\n4. Select a provider and model; set a system prompt if desired.\n5. Type your question in the input and press Enter to send.\n\n---\n\n## Configuration\n\nAll settings live under the `devmate` namespace.\n\n### Providers (devmate.providers)\n\nDefine one or more providers with models. Each model can specify which API to use (`chatCompletions` or `responses`), custom options, and optional tools (Responses API).\n\nExample (OpenAI with both APIs):\n```json\n{\n  \"devmate.providers\": [\n    {\n      \"name\": \"OpenAI\",\n      \"apiKey\": \"sk-...\",\n      \"apiUrl\": \"https://api.openai.com/v1\",\n      \"chatCompletionsUrl\": \"https://api.openai.com/v1\", \n      \"responsesUrl\": \"https://api.openai.com/v1\",\n      \"models\": [\n        {\n          \"name\": \"gpt-4o-mini (Chat Completions)\",\n          \"model_name\": \"gpt-4o-mini\",\n          \"api\": \"chatCompletions\",\n          \"options\": {\n            \"temperature\": 0.7,\n            \"max_tokens\": 1024\n          },\n          \"reasoning_output_delta_path\": \"choices[0].delta.reasoning\"\n        },\n        {\n          \"name\": \"o4-mini (Responses)\",\n          \"model_name\": \"o4-mini\",\n          \"api\": \"responses\",\n          \"tools\": [\n            { \"type\": \"web_search\" }\n          ],\n          \"options\": {\n            \"temperature\": 0.6,\n            \"max_output_tokens\": 2048\n          }\n        }\n      ]\n    }\n  ]\n}\n```\n\nNotes:\n- For Chat Completions, set `chatCompletionsUrl` (or fallback to `apiUrl`).\n- For Responses, set `responsesUrl` (or fallback to `apiUrl`).\n- `reasoning_output_delta_path` is optional and provider‑specific; it tells DevMate where to find reasoning deltas in streaming chat completions chunks.\n\n### System Prompts (devmate.prompts)\n\nDefine a list of reusable system prompts for the selector.\n\n```json\n{\n  \"devmate.prompts\": [\n    {\n      \"name\": \"Default\",\n      \"prompt\": \"You are a helpful assistant.\"\n    },\n    {\n      \"name\": \"Explain-first\",\n      \"prompt\": \"You are a meticulous assistant. First explain the reasoning, then provide the code.\"\n    }\n  ]\n}\n```\n\n### Behavior Settings\n\n```json\n{\n  \"devmate.pasteOnClick\": true,\n  \"devmate.selectedInsideCodeblock\": true,\n  \"devmate.codeblockWithLanguageId\": true,\n  \"devmate.keepConversation\": true,\n  \"devmate.timeoutLength\": 120\n}\n```\n\n- `pasteOnClick`: Click a code block in responses to paste into the editor.\n- `selectedInsideCodeblock`: Wrap editor selection in code fences when sending.\n- `codeblockWithLanguageId`: Include language id in code fences.\n- `keepConversation`: Reuse the same conversation for follow‑ups.\n- `timeoutLength`: Request timeout (seconds).\n\n---\n\n## Usage\n\n### The Chat View\n\n- Top bar: Provider and Model selectors.\n- Message list:\n  - Each message shows role and content.\n  - Checkbox includes/excludes message from the next request context.\n  - Collapse/expand individual messages. Collapsed state is preserved for YAML export/import.\n  - Inline editing for plain text messages.\n  - For “File reference” messages, a “Move reference to end” toggle appears. When enabled, the reference is moved just before your latest query on send (leaving a note in the original position).\n- Stats bar: Total tokens used across the session, current request usage, and model.\n- Bottom: System Prompt selector and the input box.\n\n### Commands\n\nFrom the Command Palette or context menus:\n\n- Ask DevMate AI Chat: `devmate.ask`\n- DevMate AI Chat: Explain selection: `devmate.explain`\n- DevMate AI Chat: Refactor selection: `devmate.refactor`\n- DevMate AI Chat: Optimize selection: `devmate.optimize`\n- DevMate AI Chat: Find problems: `devmate.findProblems`\n- DevMate AI Chat: Write documentation: `devmate.documentation`\n- Reset DevMate AI Chat conversation: `devmate.resetConversation`\n- Paste DevMate AI Chat chat (export YAML into editor): `devmate.pasteChat`\n- Use selection as DevMate AI Chat conversation (import YAML, replaces chat): `devmate.useSelectionAsChat`\n- Append selection to DevMate AI Chat conversation (import YAML, appends): `devmate.appendSelectionAsChat`\n- Append Markdown selection to DevMate AI Chat conversation (extracts images & text): `devmate.appendSelectionMarkdownAsChat`\n- Add Image to DevMate AI Chat (Explorer): `devmate.addImageToChat`\n- Add File Content to DevMate AI Chat (Explorer): `devmate.addFileToChat`\n- Add File Reference to DevMate AI Chat (Explorer): `devmate.addFileReferenceToChat`\n- Add Selected File References to Chat (from selected tree text): `devmate.addSelectedPathsAsReferences`\n\nContext menus:\n- Editor context shows most chat actions.\n- Explorer context shows file/image actions.\n\n### Working with Files and Images\n\n- Add File Content: Inserts file contents now as a code block.\n- Add File Reference: Inserts a lightweight reference (displayed nicely) and a hidden marker. Actual file content is read and injected right before sending the next prompt. You can also toggle “Move reference to end”.\n- Click inline file path (formatted as `code`): DevMate tries to open and add it automatically.\n- Images: Paste images directly into the input or add via Explorer command. Images are attached as proper `image_url` parts.\n\n### YAML Import/Export\n\n- Export: `DevMate AI Chat: Paste chat` inserts current chat as YAML into the active editor. Collapsed states and `moveToEnd` flags are included.\n- Import (replace): Select YAML in the editor → `Use selection as DevMate AI Chat conversation`.\n- Import (append): Select YAML in the editor → `Append selection to DevMate AI Chat conversation`.\n\nYAML format is a simple array of messages with `{ role, content, selected, collapsed?, moveToEnd? }`.\n\n### Streaming, Reasoning, and Stats\n\n- Output is streamed to the view.\n- Reasoning deltas are shown in a distinct color during streaming:\n  - For Responses API: the model’s “reasoning summary” can be shown and is added as a collapsed, unselected assistant message.\n  - For Chat Completions (if `reasoning_output_delta_path` provided): reasoning deltas are also shown and saved as a collapsed, unselected `<think>...</think>` message.\n- Token stats bar shows totals and per‑request usage.\n- Watchdog: If streaming stalls for ~90s, the partial output is finalized to avoid hanging.\n\n### Keyboard Shortcuts\n\n- Enter: Send query (uses editor selection if configured).\n- Ctrl+Enter (Cmd+Enter on macOS): Send without querying the editor selection (“Prompt (No Query)” path).\n\n---\n\n## Privacy & Security\n\n- DevMate sends your selected messages (including file contents, images, and references expanded at send time) to the configured provider endpoint(s). Review your content before sending.\n- Your API key is read from your VS Code settings (`devmate.providers`). Keep it secure.\n- DevMate does not transmit data anywhere else.\n\n---\n\n## Troubleshooting\n\n- “API key or API URL not set…”: Ensure `devmate.providers` is configured. Pick a provider/model in the UI.\n- Responses API errors:\n  - Requires the OpenAI SDK with Responses client support. This project targets OpenAI SDK v6+ (Responses). If you run into errors, update dependencies and rebuild.\n- No answer / stalled stream: The watchdog will finalize partial output after ~90s. Try again or check provider status.\n- Click‑to‑paste disabled: Set `devmate.pasteOnClick` to `true`.\n\n---\n\n## Known Limitations\n\n- Token estimates use `js-tiktoken` heuristics and may not match provider billing exactly.\n- Reasoning markers are visible in the stream but not saved to the final assistant answer (a separate collapsed message is added).\n- Mixed dependencies across lockfiles can cause mismatches; see [Development Guide](#development-guide) to align versions.\n\n---\n\n## Roadmap\n\n- Multi-message editing improvements\n- Model capability discovery in UI\n- More provider templates\n- Better diff/patch operations back to workspace\n\n---\n\n## Contributing\n\n- Issues and PRs are welcome.\n- Please:\n  - Describe expected vs actual behavior\n  - Include logs (DevTools / Output) if relevant\n  - For PRs, run lint/tests and keep changes focused\n\n---\n\n## Development Guide\n\n### Project Structure\n\n```\n.\n├─ media/\n│  ├─ main.js               # Webview script (UI, streaming renderer, events)\n│  ├─ styles.css            # Webview styles\n│  └─ scripts/              # Microlight, Tailwind, Showdown, DOMPurify\n├─ src/\n│  ├─ extension.ts          # VS Code activation, commands, configuration glue\n│  ├─ chatGptViewProvider.ts# Core logic, OpenAI calls, message/state management\n│  └─ types.ts              # Shared types, provider/model definitions\n├─ dist/                    # Webpack output\n├─ package.json\n├─ package-lock.json / yarn.lock\n├─ webpack.config.js\n├─ tsconfig.json\n└─ vsc-extension-quickstart.md\n```\n\nArchitecture:\n- Extension host (Node): `src/extension.ts`, `src/chatGptViewProvider.ts`\n- UI (Webview): `media/main.js` + HTML generated by provider\n- Messaging: `webview.postMessage` / `onDidReceiveMessage` channel\n\n### Build, Run, Test\n\n- Install deps:\n  ```bash\n  yarn\n  # or: npm install\n  ```\n- Build (bundle with webpack):\n  ```bash\n  yarn compile\n  # or: npm run compile\n  ```\n- Watch:\n  ```bash\n  yarn watch\n  ```\n- Launch the extension:\n  - Press F5 in VS Code (“Run Extension”)\n- Lint:\n  ```bash\n  yarn lint\n  ```\n- Tests (Mocha):\n  ```bash\n  yarn test\n  ```\n\nNote: The project currently contains both package-lock.json and yarn.lock. Use one package manager consistently to avoid version drift. If using npm, `npm run update-package-lock` can refresh locks.\n\n### Packaging & Publishing\n\n- Production bundle:\n  ```bash\n  yarn package\n  ```\n- The `vscode:prepublish` script runs the production bundle step.\n\n### Webview Messaging Protocol\n\nWebview → Extension:\n- `ready`\n- `prompt` / `promptNoQuery`\n- `pasteImage`\n- `codeSelected`\n- `checkboxChanged` (include/exclude from context)\n- `messageContentChanged` (inline edits)\n- `collapseChanged` (persist UI collapsed state)\n- `toggleMoveRefToEnd` (per-message)\n- `providerModelChanged`\n- `systemPromptChanged`\n- `forceFinalizePartial` (watchdog)\n- `fileClicked` (inline file path clicked)\n\nExtension → Webview:\n- `initialize` (providers)\n- `initialize_prompts` (system prompts)\n- `addResponse` (render content)\n- `updateResponse`\n- `clearResponse`\n- `setPrompt`\n- `updateStats` (tokens/model)\n- `resetCollapseState`\n- `setCollapsedForIndex`\n- `setMoveRefToEndForIndex`\n- Streaming:\n  - `streamStart`\n  - `appendDelta`\n  - `appendReasoningDelta`\n  - `streamEnd`\n\nSee `media/main.js` and `src/chatGptViewProvider.ts` for exact payload shapes.\n\n### Providers & APIs\n\n- Model selection drives API usage:\n  - `chatCompletions`: Uses `openai.chat.completions.create({ stream: true })`\n  - `responses`: Uses `openai.responses.stream({ ... })` (OpenAI SDK v6+)\n- Tools:\n  - Responses API “tools” can be set per model. Server-side tools (e.g., web_search) are handled by the provider. For custom tools requiring client outputs, DevMate currently submits stub outputs so the model can proceed.\n- File references:\n  - Lightweight string markers (e.g., `<!--FILE:relative/path.ext-->`) are expanded to code blocks at send time. This keeps the chat UI snappy and up-to-date with file changes on disk.\n\n---\n\n## Changelog\n\n- 1.1.0\n  - Provider/Model selectors with Chat Completions & Responses support\n  - Streaming with reasoning deltas and token stats bar\n  - File references with “Move to end” toggle and path click handling\n  - YAML import/export; Markdown selection import (with images)\n  - Image paste support; inline editing; collapse/expand messages\n\n---\n\n## License\n\nMIT © Diego Alfonso Aguilar Cardona\n\n```"
        }
      ],
      "role": "assistant"
    }
    ```
  selected: false
  collapsed: true
- role: assistant
  content: |-
    <think>**Documenting the README.md**

    I need to generate a README.md for the DevMate AI Chat VS Code extension. First, I'll cover installation, configuration, usage, commands, and provider/model settings. I'll also address system prompts and functionality like streaming and visualization. A clear example config JSON is essential, especially since the code supports both chatCompletions and responses. However, there's an inconsistency with the OpenAI SDK version noted in package.json and yarn.lock. It looks messy but is essential information for developers using Node 16.
    **Outlining README.md Structure**

    I need to provide several components for the README.md, including development commands and project architecture like the webview front-end under media/main.js with streaming features. I'll outline the folder structure and cover sections like contributing, licensing (MIT), and details on security and privacy regarding API keys.

    I should also address troubleshooting, known limitations, release notes, a roadmap, and an issue template. Adding fenced code blocks with triple backticks is important for clarity, and I’ll include sections for overview, features, requirements, and more to ensure users have comprehensive documentation.
    **Crafting the README**

    I need to create a concise yet thorough README, ensuring I include code blocks for JSON settings examples. I'll provide a sample settings array for `devmate.providers`, featuring an OpenAI example with both `chatCompletionsUrl` and `responsesUrl`, plus options like `reasoning_output_delta_path` for chat completions and related tools. 

    I want to include a section explaining "Why two APIs?" which details the usage of `devmate.settings.apiType`. I'll outline the UI features like provider and model selectors, prompt input behaviors, and file reference commands for clarity about how everything works.
    **Documenting Reference Features and Troubleshooting**

    I need to explain that references are lighter and can be expanded at send time, plus movable to the end. There are selection commands like `useSelectionAsChat` which replaces messages with YAML, and `appendSelectionAsChat` for adding messages. I’ll outline how exporting chat works with the `pasteChat` command and ensure the stats bar displays tokens and model information.

    For troubleshooting, I’ll mention issues with missing API keys or URLs, and model mismatches requiring SDK versioning. Lastly, I’ll clarify developer details about Node, Yarn, webpack usage, and coding guidelines.
    **Detailing Message Types and README Content**

    I need to list the message types exchanged between the extension and the webview, including items like `ready`, `initialize`, and `addResponse`. I’ll also provide quick documentation for these types. 

    On privacy, it's important to note that data, including images and files, may be transmitted to configured providers, but DevMate does not send information elsewhere. My plan is to include the MIT license mention, along with contribution steps for PRs, and a minimal changelog. I’ll ensure code sections are properly formatted with triple backticks and add placeholders for screenshots, while referencing the UI layout without including images.</think>
  selected: false
  collapsed: true
- role: assistant
  content: |-
    ```markdown
    # DevMate AI Chat

    Use ChatGPT, GPT‑4, and compatible APIs right inside VS Code to enhance and automate your coding with AI‑powered assistance. DevMate provides a flexible provider/model selector, rich chat UI with streaming, token stats, file/content references, images, YAML import/export, and more.

    - Publisher: `diegoaac`
    - Extension ID: `diegoaac.devmate-ai-chat`
    - License: MIT

    ---

    ## Table of Contents

    - [Features](#features)
    - [Requirements](#requirements)
    - [Installation](#installation)
    - [Quick Start](#quick-start)
    - [Configuration](#configuration)
      - [Providers (devmate.providers)](#providers-devmateproviders)
      - [System Prompts (devmate.prompts)](#system-prompts-devmateprompts)
      - [Behavior Settings](#behavior-settings)
    - [Usage](#usage)
      - [The Chat View](#the-chat-view)
      - [Commands](#commands)
      - [Working with Files and Images](#working-with-files-and-images)
      - [YAML Import/Export](#yaml-importexport)
      - [Streaming, Reasoning, and Stats](#streaming-reasoning-and-stats)
      - [Keyboard Shortcuts](#keyboard-shortcuts)
    - [Privacy & Security](#privacy--security)
    - [Troubleshooting](#troubleshooting)
    - [Known Limitations](#known-limitations)
    - [Roadmap](#roadmap)
    - [Contributing](#contributing)
    - [Development Guide](#development-guide)
      - [Project Structure](#project-structure)
      - [Build, Run, Test](#build-run-test)
      - [Packaging & Publishing](#packaging--publishing)
      - [Webview Messaging Protocol](#webview-messaging-protocol)
      - [Providers & APIs](#providers--apis)
    - [Changelog](#changelog)
    - [License](#license)

    ---

    ## Features

    - Provider and Model selectors with per‑model API type:
      - Chat Completions (e.g., `gpt-4o-mini`, compatible endpoints)
      - Responses API (OpenAI v6+ Responses with tools and reasoning)
    - Streaming output with low-latency rendering
      - Shows reasoning deltas in a distinct style while streaming (not persisted to history)
    - Token stats bar: total/used tokens and current model
    - Rich chat controls per message:
      - Include/Exclude message from context (checkbox)
      - Collapse/Expand with preview
      - Edit message content inline
      - “Move reference to end” toggle for file references
    - File workflows:
      - Add file content (code blocks) to chat
      - Add lightweight file reference (content expanded at send time)
      - Add multiple references/images from selected path lists
      - Clickable inline `code` that looks like a file path opens & adds it
    - Image support:
      - Drag/paste images into the prompt input (as image parts)
      - Add images from Explorer context menu
    - YAML import/export:
      - Export the current chat as YAML
      - Replace or append chat by selecting YAML in the editor
    - System Prompt selector (from configured prompts)
    - Click‑to‑paste any code block into the editor (configurable)

    ---

    ## Requirements

    - VS Code ≥ 1.73.0
    - A compatible AI provider account and API key (e.g., OpenAI)
    - NodeJS environment for development (see [Development Guide](#development-guide))

    ---

    ## Installation

    1. Open VS Code.
    2. Install the extension (packaged `vsix` or from Marketplace when published).
    3. Open Command Palette → “DevMate AI Chat: Ask DevMate AI Chat” (or open the “DevMate AI Chat” view from the Activity Bar).

    ---

    ## Quick Start

    1. Open Settings (Ctrl/Cmd + ,) and search for “DevMate AI Chat”.
    2. Configure at least one provider in `devmate.providers`. See example below.
    3. Open the “DevMate AI Chat” view from the Activity Bar.
    4. Select a provider and model; set a system prompt if desired.
    5. Type your question in the input and press Enter to send.

    ---

    ## Configuration

    All settings live under the `devmate` namespace.

    ### Providers (devmate.providers)

    Define one or more providers with models. Each model can specify which API to use (`chatCompletions` or `responses`), custom options, and optional tools (Responses API).

    Example (OpenAI with both APIs):
    ```json
    {
      "devmate.providers": [
        {
          "name": "OpenAI",
          "apiKey": "sk-...",
          "apiUrl": "https://api.openai.com/v1",
          "chatCompletionsUrl": "https://api.openai.com/v1", 
          "responsesUrl": "https://api.openai.com/v1",
          "models": [
            {
              "name": "gpt-4o-mini (Chat Completions)",
              "model_name": "gpt-4o-mini",
              "api": "chatCompletions",
              "options": {
                "temperature": 0.7,
                "max_tokens": 1024
              },
              "reasoning_output_delta_path": "choices[0].delta.reasoning"
            },
            {
              "name": "o4-mini (Responses)",
              "model_name": "o4-mini",
              "api": "responses",
              "tools": [
                { "type": "web_search" }
              ],
              "options": {
                "temperature": 0.6,
                "max_output_tokens": 2048
              }
            }
          ]
        }
      ]
    }
    ```

    Notes:
    - For Chat Completions, set `chatCompletionsUrl` (or fallback to `apiUrl`).
    - For Responses, set `responsesUrl` (or fallback to `apiUrl`).
    - `reasoning_output_delta_path` is optional and provider‑specific; it tells DevMate where to find reasoning deltas in streaming chat completions chunks.

    ### System Prompts (devmate.prompts)

    Define a list of reusable system prompts for the selector.

    ```json
    {
      "devmate.prompts": [
        {
          "name": "Default",
          "prompt": "You are a helpful assistant."
        },
        {
          "name": "Explain-first",
          "prompt": "You are a meticulous assistant. First explain the reasoning, then provide the code."
        }
      ]
    }
    ```

    ### Behavior Settings

    ```json
    {
      "devmate.pasteOnClick": true,
      "devmate.selectedInsideCodeblock": true,
      "devmate.codeblockWithLanguageId": true,
      "devmate.keepConversation": true,
      "devmate.timeoutLength": 120
    }
    ```

    - `pasteOnClick`: Click a code block in responses to paste into the editor.
    - `selectedInsideCodeblock`: Wrap editor selection in code fences when sending.
    - `codeblockWithLanguageId`: Include language id in code fences.
    - `keepConversation`: Reuse the same conversation for follow‑ups.
    - `timeoutLength`: Request timeout (seconds).

    ---

    ## Usage

    ### The Chat View

    - Top bar: Provider and Model selectors.
    - Message list:
      - Each message shows role and content.
      - Checkbox includes/excludes message from the next request context.
      - Collapse/expand individual messages. Collapsed state is preserved for YAML export/import.
      - Inline editing for plain text messages.
      - For “File reference” messages, a “Move reference to end” toggle appears. When enabled, the reference is moved just before your latest query on send (leaving a note in the original position).
    - Stats bar: Total tokens used across the session, current request usage, and model.
    - Bottom: System Prompt selector and the input box.

    ### Commands

    From the Command Palette or context menus:

    - Ask DevMate AI Chat: `devmate.ask`
    - DevMate AI Chat: Explain selection: `devmate.explain`
    - DevMate AI Chat: Refactor selection: `devmate.refactor`
    - DevMate AI Chat: Optimize selection: `devmate.optimize`
    - DevMate AI Chat: Find problems: `devmate.findProblems`
    - DevMate AI Chat: Write documentation: `devmate.documentation`
    - Reset DevMate AI Chat conversation: `devmate.resetConversation`
    - Paste DevMate AI Chat chat (export YAML into editor): `devmate.pasteChat`
    - Use selection as DevMate AI Chat conversation (import YAML, replaces chat): `devmate.useSelectionAsChat`
    - Append selection to DevMate AI Chat conversation (import YAML, appends): `devmate.appendSelectionAsChat`
    - Append Markdown selection to DevMate AI Chat conversation (extracts images & text): `devmate.appendSelectionMarkdownAsChat`
    - Add Image to DevMate AI Chat (Explorer): `devmate.addImageToChat`
    - Add File Content to DevMate AI Chat (Explorer): `devmate.addFileToChat`
    - Add File Reference to DevMate AI Chat (Explorer): `devmate.addFileReferenceToChat`
    - Add Selected File References to Chat (from selected tree text): `devmate.addSelectedPathsAsReferences`

    Context menus:
    - Editor context shows most chat actions.
    - Explorer context shows file/image actions.

    ### Working with Files and Images

    - Add File Content: Inserts file contents now as a code block.
    - Add File Reference: Inserts a lightweight reference (displayed nicely) and a hidden marker. Actual file content is read and injected right before sending the next prompt. You can also toggle “Move reference to end”.
    - Click inline file path (formatted as `code`): DevMate tries to open and add it automatically.
    - Images: Paste images directly into the input or add via Explorer command. Images are attached as proper `image_url` parts.

    ### YAML Import/Export

    - Export: `DevMate AI Chat: Paste chat` inserts current chat as YAML into the active editor. Collapsed states and `moveToEnd` flags are included.
    - Import (replace): Select YAML in the editor → `Use selection as DevMate AI Chat conversation`.
    - Import (append): Select YAML in the editor → `Append selection to DevMate AI Chat conversation`.

    YAML format is a simple array of messages with `{ role, content, selected, collapsed?, moveToEnd? }`.

    ### Streaming, Reasoning, and Stats

    - Output is streamed to the view.
    - Reasoning deltas are shown in a distinct color during streaming:
      - For Responses API: the model’s “reasoning summary” can be shown and is added as a collapsed, unselected assistant message.
      - For Chat Completions (if `reasoning_output_delta_path` provided): reasoning deltas are also shown and saved as a collapsed, unselected `<think>...</think>` message.
    - Token stats bar shows totals and per‑request usage.
    - Watchdog: If streaming stalls for ~90s, the partial output is finalized to avoid hanging.

    ### Keyboard Shortcuts

    - Enter: Send query (uses editor selection if configured).
    - Ctrl+Enter (Cmd+Enter on macOS): Send without querying the editor selection (“Prompt (No Query)” path).

    ---

    ## Privacy & Security

    - DevMate sends your selected messages (including file contents, images, and references expanded at send time) to the configured provider endpoint(s). Review your content before sending.
    - Your API key is read from your VS Code settings (`devmate.providers`). Keep it secure.
    - DevMate does not transmit data anywhere else.

    ---

    ## Troubleshooting

    - “API key or API URL not set…”: Ensure `devmate.providers` is configured. Pick a provider/model in the UI.
    - Responses API errors:
      - Requires the OpenAI SDK with Responses client support. This project targets OpenAI SDK v6+ (Responses). If you run into errors, update dependencies and rebuild.
    - No answer / stalled stream: The watchdog will finalize partial output after ~90s. Try again or check provider status.
    - Click‑to‑paste disabled: Set `devmate.pasteOnClick` to `true`.

    ---

    ## Known Limitations

    - Token estimates use `js-tiktoken` heuristics and may not match provider billing exactly.
    - Reasoning markers are visible in the stream but not saved to the final assistant answer (a separate collapsed message is added).
    - Mixed dependencies across lockfiles can cause mismatches; see [Development Guide](#development-guide) to align versions.

    ---

    ## Roadmap

    - Multi-message editing improvements
    - Model capability discovery in UI
    - More provider templates
    - Better diff/patch operations back to workspace

    ---

    ## Contributing

    - Issues and PRs are welcome.
    - Please:
      - Describe expected vs actual behavior
      - Include logs (DevTools / Output) if relevant
      - For PRs, run lint/tests and keep changes focused

    ---

    ## Development Guide

    ### Project Structure

    ```
    .
    ├─ media/
    │  ├─ main.js               # Webview script (UI, streaming renderer, events)
    │  ├─ styles.css            # Webview styles
    │  └─ scripts/              # Microlight, Tailwind, Showdown, DOMPurify
    ├─ src/
    │  ├─ extension.ts          # VS Code activation, commands, configuration glue
    │  ├─ chatGptViewProvider.ts# Core logic, OpenAI calls, message/state management
    │  └─ types.ts              # Shared types, provider/model definitions
    ├─ dist/                    # Webpack output
    ├─ package.json
    ├─ package-lock.json / yarn.lock
    ├─ webpack.config.js
    ├─ tsconfig.json
    └─ vsc-extension-quickstart.md
    ```

    Architecture:
    - Extension host (Node): `src/extension.ts`, `src/chatGptViewProvider.ts`
    - UI (Webview): `media/main.js` + HTML generated by provider
    - Messaging: `webview.postMessage` / `onDidReceiveMessage` channel

    ### Build, Run, Test

    - Install deps:
      ```bash
      yarn
      # or: npm install
      ```
    - Build (bundle with webpack):
      ```bash
      yarn compile
      # or: npm run compile
      ```
    - Watch:
      ```bash
      yarn watch
      ```
    - Launch the extension:
      - Press F5 in VS Code (“Run Extension”)
    - Lint:
      ```bash
      yarn lint
      ```
    - Tests (Mocha):
      ```bash
      yarn test
      ```

    Note: The project currently contains both package-lock.json and yarn.lock. Use one package manager consistently to avoid version drift. If using npm, `npm run update-package-lock` can refresh locks.

    ### Packaging & Publishing

    - Production bundle:
      ```bash
      yarn package
      ```
    - The `vscode:prepublish` script runs the production bundle step.

    ### Webview Messaging Protocol

    Webview → Extension:
    - `ready`
    - `prompt` / `promptNoQuery`
    - `pasteImage`
    - `codeSelected`
    - `checkboxChanged` (include/exclude from context)
    - `messageContentChanged` (inline edits)
    - `collapseChanged` (persist UI collapsed state)
    - `toggleMoveRefToEnd` (per-message)
    - `providerModelChanged`
    - `systemPromptChanged`
    - `forceFinalizePartial` (watchdog)
    - `fileClicked` (inline file path clicked)

    Extension → Webview:
    - `initialize` (providers)
    - `initialize_prompts` (system prompts)
    - `addResponse` (render content)
    - `updateResponse`
    - `clearResponse`
    - `setPrompt`
    - `updateStats` (tokens/model)
    - `resetCollapseState`
    - `setCollapsedForIndex`
    - `setMoveRefToEndForIndex`
    - Streaming:
      - `streamStart`
      - `appendDelta`
      - `appendReasoningDelta`
      - `streamEnd`

    See `media/main.js` and `src/chatGptViewProvider.ts` for exact payload shapes.

    ### Providers & APIs

    - Model selection drives API usage:
      - `chatCompletions`: Uses `openai.chat.completions.create({ stream: true })`
      - `responses`: Uses `openai.responses.stream({ ... })` (OpenAI SDK v6+)
    - Tools:
      - Responses API “tools” can be set per model. Server-side tools (e.g., web_search) are handled by the provider. For custom tools requiring client outputs, DevMate currently submits stub outputs so the model can proceed.
    - File references:
      - Lightweight string markers (e.g., `<!--FILE:relative/path.ext-->`) are expanded to code blocks at send time. This keeps the chat UI snappy and up-to-date with file changes on disk.

    ---

    ## Changelog

    - 1.1.0
      - Provider/Model selectors with Chat Completions & Responses support
      - Streaming with reasoning deltas and token stats bar
      - File references with “Move to end” toggle and path click handling
      - YAML import/export; Markdown selection import (with images)
      - Image paste support; inline editing; collapse/expand messages

    ---

    ## License

    MIT © Diego Alfonso Aguilar Cardona

    ```
  selected: true
  collapsed: false
- role: user
  content: 'Note: reference to media/main.js was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to package-lock.json was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to package.json was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to src/chatGptViewProvider.ts was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to src/extension.ts was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to src/types.ts was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to tsconfig.json was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to vsc-extension-quickstart.md was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to webpack.config.js was here.'
  selected: true
  collapsed: true
- role: user
  content: 'Note: reference to yarn.lock was here.'
  selected: true
  collapsed: true
- role: user
  content: I use "vsce package" to create the extension file.  Add this to the Readme, provide me the full readme again.
  selected: true
  collapsed: false
- role: assistant
  content: |-
    Responses message output item:
    ```json
    {
      "id": "msg_0dab994766963b2800692a3610517c819f8ab326ccf7f8faa6",
      "type": "message",
      "status": "completed",
      "content": [
        {
          "type": "output_text",
          "annotations": [],
          "logprobs": [],
          "text": "```markdown\n# DevMate AI Chat\n\nUse ChatGPT, GPT‑4, and compatible APIs right inside VS Code to enhance and automate your coding with AI‑powered assistance. DevMate provides a flexible provider/model selector, rich chat UI with streaming, reasoning deltas, token stats, file/content references, images, YAML import/export, and more.\n\n- Publisher: diegoaac\n- Extension ID: diegoaac.devmate-ai-chat\n- License: MIT\n- Min VS Code: 1.73.0\n\n---\n\n## Table of Contents\n\n- [Features](#features)\n- [Screens & UX Highlights](#screens--ux-highlights)\n- [Requirements](#requirements)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n  - [Providers (devmate.providers)](#providers-devmateproviders)\n  - [System Prompts (devmate.prompts)](#system-prompts-devmateprompts)\n  - [Behavior Settings](#behavior-settings)\n- [Usage](#usage)\n  - [The Chat View](#the-chat-view)\n  - [Commands & Menus](#commands--menus)\n  - [Working with Files and Images](#working-with-files-and-images)\n  - [YAML Import/Export](#yaml-importexport)\n  - [Streaming, Reasoning, and Stats](#streaming-reasoning-and-stats)\n  - [Keyboard Shortcuts](#keyboard-shortcuts)\n- [Privacy & Security](#privacy--security)\n- [Troubleshooting](#troubleshooting)\n- [Known Limitations](#known-limitations)\n- [Roadmap](#roadmap)\n- [Contributing](#contributing)\n- [Development Guide](#development-guide)\n  - [Project Structure](#project-structure)\n  - [Build, Run, Test](#build-run-test)\n  - [Packaging & Publishing (vsce)](#packaging--publishing-vsce)\n  - [Webview Messaging Protocol](#webview-messaging-protocol)\n  - [Providers & APIs](#providers--apis)\n  - [Compatibility Notes](#compatibility-notes)\n- [Changelog](#changelog)\n- [License](#license)\n\n---\n\n## Features\n\n- Provider and Model selectors with per‑model API type:\n  - Chat Completions (e.g., gpt-4o-mini, compatible endpoints)\n  - Responses API (OpenAI v6+ Responses with tools and reasoning)\n- Streaming output with low-latency rendering\n  - Shows reasoning deltas in a distinct style while streaming (not persisted to history)\n- Token stats bar: total, last used (prompt+completion), and current model\n- Rich chat controls per message:\n  - Include/Exclude message from context (checkbox)\n  - Collapse/Expand with preview\n  - Edit message content inline\n  - “Move reference to end” toggle for file references\n- File workflows:\n  - Add file content (code blocks) to chat\n  - Add lightweight file reference (content expanded at send time)\n  - Add multiple references/images from selected path lists\n  - Clickable inline code that looks like a file path opens & adds it\n- Image support:\n  - Drag/paste images into the prompt input (as image parts)\n  - Add images from Explorer context menu\n- YAML import/export:\n  - Export the current chat as YAML\n  - Replace or append chat by selecting YAML in the editor\n- System Prompt selector (from configured prompts)\n- Click‑to‑paste any code block into the editor (configurable)\n- Watchdog to auto‑finalize stalled streams\n\n---\n\n## Screens & UX Highlights\n\n- Fast streaming renderer with truncated view (shows tail of long outputs, keeps code fences balanced)\n- Reasoning deltas highlighted while streaming; saved into a collapsed <think> message when done\n- Each message renders in its own Shadow DOM for safer, isolated markup with sanitized HTML\n\n---\n\n## Requirements\n\n- VS Code ≥ 1.73.0\n- An AI provider account and API key (e.g., OpenAI)\n- Node.js (for development/build)\n- For Responses API features: OpenAI SDK v6+\n\n---\n\n## Installation\n\n- From VSIX:\n  - Build/package (see Development Guide), then install:\n    ```bash\n    code --install-extension devmate-ai-chat-*.vsix\n    ```\n- From Marketplace:\n  - When published, search for “DevMate AI Chat” and install.\n\nOpen Command Palette → “DevMate AI Chat: Ask DevMate AI Chat” or open the “DevMate AI Chat” view from the Activity Bar.\n\n---\n\n## Quick Start\n\n1. Open Settings and search for “DevMate AI Chat”.\n2. Configure at least one provider in devmate.providers (see below).\n3. Open the “DevMate AI Chat” view (Activity Bar).\n4. Select a provider and model; set a system prompt if desired.\n5. Type your question and press Enter to send.\n\n---\n\n## Configuration\n\nAll settings live under the devmate namespace.\n\n### Providers (devmate.providers)\n\nDefine one or more providers with models. Each model can specify which API to use (chatCompletions or responses), custom options, and optional tools (Responses API).\n\nExample:\n```json\n{\n  \"devmate.providers\": [\n    {\n      \"name\": \"OpenAI\",\n      \"apiKey\": \"sk-...\",\n      \"apiUrl\": \"https://api.openai.com/v1\",\n      \"chatCompletionsUrl\": \"https://api.openai.com/v1\",\n      \"responsesUrl\": \"https://api.openai.com/v1\",\n      \"models\": [\n        {\n          \"name\": \"gpt-4o-mini (Chat Completions)\",\n          \"model_name\": \"gpt-4o-mini\",\n          \"api\": \"chatCompletions\",\n          \"options\": {\n            \"temperature\": 0.7,\n            \"max_tokens\": 1024\n          },\n          \"reasoning_output_delta_path\": \"choices[0].delta.reasoning\"\n        },\n        {\n          \"name\": \"o4-mini (Responses)\",\n          \"model_name\": \"o4-mini\",\n          \"api\": \"responses\",\n          \"tools\": [\n            { \"type\": \"web_search\" }\n          ],\n          \"options\": {\n            \"temperature\": 0.6,\n            \"max_output_tokens\": 2048,\n            \"reasoning\": { \"summary\": \"auto\" }\n          }\n        }\n      ]\n    }\n  ]\n}\n```\n\nNotes:\n- For Chat Completions, set chatCompletionsUrl (or fallback to apiUrl).\n- For Responses, set responsesUrl (or fallback to apiUrl).\n- reasoning_output_delta_path is optional and provider‑specific; it tells DevMate where to find reasoning deltas in streaming chat completion chunks.\n\n### System Prompts (devmate.prompts)\n\nDefine a list of reusable system prompts for the selector.\n\n```json\n{\n  \"devmate.prompts\": [\n    { \"name\": \"Default\", \"prompt\": \"You are a helpful assistant.\" },\n    { \"name\": \"Explain-first\", \"prompt\": \"You are a meticulous assistant. First explain the reasoning, then provide the code.\" }\n  ]\n}\n```\n\n### Behavior Settings\n\n```json\n{\n  \"devmate.pasteOnClick\": true,\n  \"devmate.selectedInsideCodeblock\": true,\n  \"devmate.codeblockWithLanguageId\": true,\n  \"devmate.keepConversation\": true,\n  \"devmate.timeoutLength\": 120\n}\n```\n\n- pasteOnClick: Click a code block in responses to paste into the editor.\n- selectedInsideCodeblock: Wrap editor selection in code fences when sending.\n- codeblockWithLanguageId: Include language id in code fences.\n- keepConversation: Reuse the same conversation for follow‑ups.\n- timeoutLength: Request timeout (seconds).\n\n---\n\n## Usage\n\n### The Chat View\n\n- Top bar: Provider and Model selectors.\n- Message list:\n  - Each message shows role and content, with a checkbox to include/exclude from next context.\n  - Collapse/expand with preview. Collapsed state is preserved for YAML export/import.\n  - Inline editing for plain text messages.\n  - For “File reference” messages, a “Move reference to end” toggle appears. When enabled, the reference is moved just before your latest query on send (leaving a note where it was).\n- Stats bar: Total tokens used across the session, tokens used this request (prompt+completion), and model.\n- Bottom: System Prompt selector and the input box.\n\n### Commands & Menus\n\nCommands:\n- devmate.ask — Ask DevMate AI Chat\n- devmate.explain — Explain selection\n- devmate.refactor — Refactor selection\n- devmate.optimize — Optimize selection\n- devmate.findProblems — Find problems\n- devmate.documentation — Write documentation\n- devmate.resetConversation — Reset conversation\n- devmate.pasteChat — Paste chat (export YAML into editor)\n- devmate.useSelectionAsChat — Use selection as conversation (import YAML, replaces)\n- devmate.appendSelectionAsChat — Append selection as conversation (import YAML, appends)\n- devmate.appendSelectionMarkdownAsChat — Append Markdown selection as chat (images + text)\n- devmate.addImageToChat — Add image (Explorer)\n- devmate.addFileToChat — Add file content (Explorer)\n- devmate.addFileReferenceToChat — Add file reference (Explorer)\n- devmate.addSelectedPathsAsReferences — Add multiple references/images from selected tree text\n\nMenus:\n- Editor context: Most chat actions (explain/refactor/optimize/etc.)\n- Explorer context: Add image/file content/file reference\n\n### Working with Files and Images\n\n- Add File Content: Inserts file contents immediately as a code block.\n- Add File Reference: Inserts a lightweight reference; actual content is injected right before sending the next prompt. Toggle “Move reference to end” to auto‑pin near the query.\n- Inline file paths in responses: Any inline code that looks like a path becomes clickable and can be added automatically.\n- Images: Paste images into the prompt input or add via Explorer context menu. Images are attached as proper image parts.\n\n### YAML Import/Export\n\n- Export: “Paste chat” inserts the current chat as YAML into the active editor. Collapsed states and moveToEnd flags are included.\n- Import (replace): Select YAML → “Use selection as DevMate AI Chat conversation”.\n- Import (append): Select YAML → “Append selection to DevMate AI Chat conversation”.\n\nYAML format is an array of messages with:\n```yaml\n- role: user|assistant|system\n  content: string | parts\n  selected: true|false\n  collapsed: true|false # optional\n  moveToEnd: true|false # optional\n```\n\n### Streaming, Reasoning, and Stats\n\n- Output is streamed to the view.\n- Reasoning deltas are shown in a distinct color during streaming and are saved as a collapsed <think> assistant message after completion.\n- Token stats bar shows totals and per‑request usage.\n- Watchdog: If streaming stalls for ~90s, the partial output is finalized to avoid hanging.\n\n### Keyboard Shortcuts\n\n- Enter: Send query (uses editor selection if configured).\n- Ctrl+Enter (Cmd+Enter on macOS): Send without querying the editor selection (Prompt No Query).\n\n---\n\n## Privacy & Security\n\n- DevMate sends your selected messages (including file contents, images, and references expanded at send time) to the configured provider endpoint(s). Review your content before sending.\n- Your API key is read from your VS Code settings (devmate.providers). Keep it secure.\n- DevMate does not transmit data anywhere else.\n\n---\n\n## Troubleshooting\n\n- “API key or API URL not set…”: Ensure devmate.providers is configured. Pick a provider/model in the UI.\n- Responses API errors:\n  - Requires OpenAI SDK v6+ (Responses). Update dependencies and rebuild if needed.\n- Stalled stream:\n  - The watchdog finalizes partial output after ~90s. Try again or check provider status.\n- Click‑to‑paste disabled:\n  - Set devmate.pasteOnClick to true.\n\n---\n\n## Known Limitations\n\n- Token estimates use js‑tiktoken heuristics and may not match provider billing exactly.\n- Reasoning markers are visible in the stream but not saved in the final answer (saved separately in a collapsed <think> message).\n- Mixed lockfiles (npm/yarn) or SDK versions can cause mismatches (see Compatibility Notes).\n\n---\n\n## Roadmap\n\n- Multi‑message editing improvements\n- Model capability discovery in UI\n- More provider templates\n- Better diff/patch operations back to workspace\n\n---\n\n## Contributing\n\nIssues and PRs are welcome. Please:\n- Describe expected vs. actual behavior\n- Include logs (DevTools / Output) if relevant\n- For PRs, run lint/tests and keep changes focused\n\n---\n\n## Development Guide\n\n### Project Structure\n\n```\n.\n├─ media/\n│  ├─ main.js               # Webview script (UI, streaming renderer, events, sanitization)\n│  ├─ styles.css            # Webview styles\n│  └─ scripts/              # Microlight, Tailwind, Showdown, DOMPurify\n├─ src/\n│  ├─ extension.ts          # Activation, commands, configuration glue\n│  ├─ chatGptViewProvider.ts# Core chat logic, OpenAI calls, messages/state\n│  └─ types.ts              # Shared types, provider/model definitions\n├─ dist/                    # Webpack output (extension.js)\n├─ package.json\n├─ package-lock.json / yarn.lock\n├─ webpack.config.js\n├─ tsconfig.json\n└─ vsc-extension-quickstart.md\n```\n\nArchitecture:\n- Extension host (Node): src/extension.ts, src/chatGptViewProvider.ts\n- UI (Webview): media/main.js + HTML generated by provider\n- Messaging: webview.postMessage / onDidReceiveMessage\n\n### Build, Run, Test\n\n- Install deps:\n  ```bash\n  yarn\n  # or: npm install\n  ```\n- Build (bundle with webpack):\n  ```bash\n  yarn compile\n  # or: npm run compile\n  ```\n- Watch:\n  ```bash\n  yarn watch\n  ```\n- Launch the extension:\n  - Press F5 in VS Code (“Run Extension”)\n- Lint:\n  ```bash\n  yarn lint\n  ```\n- Tests (Mocha):\n  ```bash\n  yarn test\n  ```\n\nNote: The repo contains both package-lock.json and yarn.lock. Use one package manager consistently to avoid version drift. If using npm, you can refresh the lock with:\n```bash\nnpm run update-package-lock\n```\n\n### Packaging & Publishing (vsce)\n\nThis project is packaged with vsce (Visual Studio Code Extension Manager).\n\n- Install vsce (globally):\n  ```bash\n  npm install -g @vscode/vsce\n  ```\n- Build the bundle first:\n  ```bash\n  yarn compile\n  # or: npm run compile\n  ```\n- Create the .vsix package:\n  ```bash\n  vsce package\n  ```\n  This produces devmate-ai-chat-<version>.vsix in the project root.\n\n- Install the VSIX locally:\n  ```bash\n  code --install-extension devmate-ai-chat-*.vsix\n  ```\n\nNotes:\n- vsce runs the vscode:prepublish script automatically if defined (this project’s prepublish bundles with webpack in production mode).\n- To publish to the Marketplace, follow:\n  https://code.visualstudio.com/api/working-with-extensions/publishing-extension\n\n### Webview Messaging Protocol\n\nWebview → Extension:\n- ready\n- prompt / promptNoQuery\n- pasteImage\n- codeSelected\n- checkboxChanged\n- messageContentChanged\n- collapseChanged\n- toggleMoveRefToEnd\n- providerModelChanged\n- systemPromptChanged\n- forceFinalizePartial\n- fileClicked\n\nExtension → Webview:\n- initialize (providers)\n- initialize_prompts (system prompts)\n- addResponse (render content)\n- updateResponse\n- clearResponse\n- setPrompt\n- updateStats (tokens/model)\n- resetCollapseState\n- setCollapsedForIndex\n- setMoveRefToEndForIndex\n- Streaming:\n  - streamStart\n  - appendDelta\n  - appendReasoningDelta\n  - streamEnd\n\nSee media/main.js and src/chatGptViewProvider.ts for exact payload shapes.\n\n### Providers & APIs\n\n- Model selection drives API usage:\n  - chatCompletions: openai.chat.completions.create({ stream: true, ... })\n  - responses: openai.responses.stream({ model, input, tools?, reasoning?, ... })\n- Tools (Responses API):\n  - Server-side tools like web_search are handled by the provider.\n  - Client-side custom tools are stubbed with a deterministic output so the model can proceed.\n- File references:\n  - Lightweight string markers (e.g., <!--FILE:relative/path.ext-->) are expanded to code blocks at send time using the latest on-disk file contents.\n\n### Compatibility Notes\n\n- OpenAI SDK:\n  - This project targets OpenAI SDK v6+ for Responses API features. Ensure your installed version is ≥ 6 if you intend to use responses.stream().\n  - If you see dependency mismatches (e.g., older openai versions in your lockfile), align by installing:\n    ```bash\n    npm install openai@^6\n    # or\n    yarn add openai@^6\n    ```\n- Mixed lockfiles:\n  - Prefer either npm or yarn. Remove the other lockfile to avoid version drift.\n\n---\n\n## Changelog\n\n- 1.1.0\n  - Provider/Model selectors with Chat Completions & Responses support\n  - Streaming with reasoning deltas and token stats bar\n  - File references with “Move to end” toggle and path click handling\n  - YAML import/export; Markdown selection import (with images)\n  - Image paste support; inline editing; collapse/expand messages\n  - Streaming watchdog for stalled responses\n\n---\n\n## License\n\nMIT © Diego Alfonso Aguilar Cardona\n```"
        }
      ],
      "role": "assistant"
    }
    ```
  selected: false
  collapsed: true
- role: assistant
  content: |-
    <think>**Updating README.md**

    I need to provide comprehensive content for the README.md. This includes sections for both users and developers, and I’ll emphasize that the user utilizes "vsce package" to create the extension file. It’s essential to include instructions for Packaging & Publishing with vsce. I must also ensure to reflect current project details. There’s a version mismatch in dependencies noted in package.json, package-lock, and yarn.lock, which I'll keep consistent. I’ll document the 'devmate' settings primarily in the README as well.
    **Detailing Webview Features and Packaging Instructions**

    I’m going to keep the webview features noted in media/main.js. I need to add packaging instructions for vsce, which is the Visual Studio Code Extension Manager. That includes telling users to install vsce with `npm install -g @vscode/vsce`, then running `yarn compile` followed by `vsce package` to create the .vsix file. I'll also mention that the 'vscode:prepublish' package script runs `yarn run package` for webpack production. 

    It's important to note compatibility with the minimum VS Code version of 1.73.0 and Node 16 for @types/node 16.x. I'll remind users that the code relies on OpenAI v6 for its responses and streaming, and they need to install openai >= 6.0.0. Lastly, I’ll highlight testing with mocha even though test paths aren’t specified.
    **Updating README Sections**

    I need to add a "Security" section focusing on the keys used, along with a "Commands & Menus" list and a "Known Limitations" section that we already have. I’ll also add the MIT license and publisher information. It’s essential to include a mention of the project structure and differentiate code snippets with triple backticks as requested by the developer. I’ll craft the updated README to include packaging instructions for vsce and explain the "vsce package" process in the Packaging & Publishing section. Finally, I’ll ensure that streaming details from "media/main.js" are included.</think>
  selected: false
  collapsed: true
- role: assistant
  content: |-
    ```markdown
    # DevMate AI Chat

    Use ChatGPT, GPT‑4, and compatible APIs right inside VS Code to enhance and automate your coding with AI‑powered assistance. DevMate provides a flexible provider/model selector, rich chat UI with streaming, reasoning deltas, token stats, file/content references, images, YAML import/export, and more.

    - Publisher: diegoaac
    - Extension ID: diegoaac.devmate-ai-chat
    - License: MIT
    - Min VS Code: 1.73.0

    ---

    ## Table of Contents

    - [Features](#features)
    - [Screens & UX Highlights](#screens--ux-highlights)
    - [Requirements](#requirements)
    - [Installation](#installation)
    - [Quick Start](#quick-start)
    - [Configuration](#configuration)
      - [Providers (devmate.providers)](#providers-devmateproviders)
      - [System Prompts (devmate.prompts)](#system-prompts-devmateprompts)
      - [Behavior Settings](#behavior-settings)
    - [Usage](#usage)
      - [The Chat View](#the-chat-view)
      - [Commands & Menus](#commands--menus)
      - [Working with Files and Images](#working-with-files-and-images)
      - [YAML Import/Export](#yaml-importexport)
      - [Streaming, Reasoning, and Stats](#streaming-reasoning-and-stats)
      - [Keyboard Shortcuts](#keyboard-shortcuts)
    - [Privacy & Security](#privacy--security)
    - [Troubleshooting](#troubleshooting)
    - [Known Limitations](#known-limitations)
    - [Roadmap](#roadmap)
    - [Contributing](#contributing)
    - [Development Guide](#development-guide)
      - [Project Structure](#project-structure)
      - [Build, Run, Test](#build-run-test)
      - [Packaging & Publishing (vsce)](#packaging--publishing-vsce)
      - [Webview Messaging Protocol](#webview-messaging-protocol)
      - [Providers & APIs](#providers--apis)
      - [Compatibility Notes](#compatibility-notes)
    - [Changelog](#changelog)
    - [License](#license)

    ---

    ## Features

    - Provider and Model selectors with per‑model API type:
      - Chat Completions (e.g., gpt-4o-mini, compatible endpoints)
      - Responses API (OpenAI v6+ Responses with tools and reasoning)
    - Streaming output with low-latency rendering
      - Shows reasoning deltas in a distinct style while streaming (not persisted to history)
    - Token stats bar: total, last used (prompt+completion), and current model
    - Rich chat controls per message:
      - Include/Exclude message from context (checkbox)
      - Collapse/Expand with preview
      - Edit message content inline
      - “Move reference to end” toggle for file references
    - File workflows:
      - Add file content (code blocks) to chat
      - Add lightweight file reference (content expanded at send time)
      - Add multiple references/images from selected path lists
      - Clickable inline code that looks like a file path opens & adds it
    - Image support:
      - Drag/paste images into the prompt input (as image parts)
      - Add images from Explorer context menu
    - YAML import/export:
      - Export the current chat as YAML
      - Replace or append chat by selecting YAML in the editor
    - System Prompt selector (from configured prompts)
    - Click‑to‑paste any code block into the editor (configurable)
    - Watchdog to auto‑finalize stalled streams

    ---

    ## Screens & UX Highlights

    - Fast streaming renderer with truncated view (shows tail of long outputs, keeps code fences balanced)
    - Reasoning deltas highlighted while streaming; saved into a collapsed <think> message when done
    - Each message renders in its own Shadow DOM for safer, isolated markup with sanitized HTML

    ---

    ## Requirements

    - VS Code ≥ 1.73.0
    - An AI provider account and API key (e.g., OpenAI)
    - Node.js (for development/build)
    - For Responses API features: OpenAI SDK v6+

    ---

    ## Installation

    - From VSIX:
      - Build/package (see Development Guide), then install:
        ```bash
        code --install-extension devmate-ai-chat-*.vsix
        ```
    - From Marketplace:
      - When published, search for “DevMate AI Chat” and install.

    Open Command Palette → “DevMate AI Chat: Ask DevMate AI Chat” or open the “DevMate AI Chat” view from the Activity Bar.

    ---

    ## Quick Start

    1. Open Settings and search for “DevMate AI Chat”.
    2. Configure at least one provider in devmate.providers (see below).
    3. Open the “DevMate AI Chat” view (Activity Bar).
    4. Select a provider and model; set a system prompt if desired.
    5. Type your question and press Enter to send.

    ---

    ## Configuration

    All settings live under the devmate namespace.

    ### Providers (devmate.providers)

    Define one or more providers with models. Each model can specify which API to use (chatCompletions or responses), custom options, and optional tools (Responses API).

    Example:
    ```json
    {
      "devmate.providers": [
        {
          "name": "OpenAI",
          "apiKey": "sk-...",
          "apiUrl": "https://api.openai.com/v1",
          "chatCompletionsUrl": "https://api.openai.com/v1",
          "responsesUrl": "https://api.openai.com/v1",
          "models": [
            {
              "name": "gpt-4o-mini (Chat Completions)",
              "model_name": "gpt-4o-mini",
              "api": "chatCompletions",
              "options": {
                "temperature": 0.7,
                "max_tokens": 1024
              },
              "reasoning_output_delta_path": "choices[0].delta.reasoning"
            },
            {
              "name": "o4-mini (Responses)",
              "model_name": "o4-mini",
              "api": "responses",
              "tools": [
                { "type": "web_search" }
              ],
              "options": {
                "temperature": 0.6,
                "max_output_tokens": 2048,
                "reasoning": { "summary": "auto" }
              }
            }
          ]
        }
      ]
    }
    ```

    Notes:
    - For Chat Completions, set chatCompletionsUrl (or fallback to apiUrl).
    - For Responses, set responsesUrl (or fallback to apiUrl).
    - reasoning_output_delta_path is optional and provider‑specific; it tells DevMate where to find reasoning deltas in streaming chat completion chunks.

    ### System Prompts (devmate.prompts)

    Define a list of reusable system prompts for the selector.

    ```json
    {
      "devmate.prompts": [
        { "name": "Default", "prompt": "You are a helpful assistant." },
        { "name": "Explain-first", "prompt": "You are a meticulous assistant. First explain the reasoning, then provide the code." }
      ]
    }
    ```

    ### Behavior Settings

    ```json
    {
      "devmate.pasteOnClick": true,
      "devmate.selectedInsideCodeblock": true,
      "devmate.codeblockWithLanguageId": true,
      "devmate.keepConversation": true,
      "devmate.timeoutLength": 120
    }
    ```

    - pasteOnClick: Click a code block in responses to paste into the editor.
    - selectedInsideCodeblock: Wrap editor selection in code fences when sending.
    - codeblockWithLanguageId: Include language id in code fences.
    - keepConversation: Reuse the same conversation for follow‑ups.
    - timeoutLength: Request timeout (seconds).

    ---

    ## Usage

    ### The Chat View

    - Top bar: Provider and Model selectors.
    - Message list:
      - Each message shows role and content, with a checkbox to include/exclude from next context.
      - Collapse/expand with preview. Collapsed state is preserved for YAML export/import.
      - Inline editing for plain text messages.
      - For “File reference” messages, a “Move reference to end” toggle appears. When enabled, the reference is moved just before your latest query on send (leaving a note where it was).
    - Stats bar: Total tokens used across the session, tokens used this request (prompt+completion), and model.
    - Bottom: System Prompt selector and the input box.

    ### Commands & Menus

    Commands:
    - devmate.ask — Ask DevMate AI Chat
    - devmate.explain — Explain selection
    - devmate.refactor — Refactor selection
    - devmate.optimize — Optimize selection
    - devmate.findProblems — Find problems
    - devmate.documentation — Write documentation
    - devmate.resetConversation — Reset conversation
    - devmate.pasteChat — Paste chat (export YAML into editor)
    - devmate.useSelectionAsChat — Use selection as conversation (import YAML, replaces)
    - devmate.appendSelectionAsChat — Append selection as conversation (import YAML, appends)
    - devmate.appendSelectionMarkdownAsChat — Append Markdown selection as chat (images + text)
    - devmate.addImageToChat — Add image (Explorer)
    - devmate.addFileToChat — Add file content (Explorer)
    - devmate.addFileReferenceToChat — Add file reference (Explorer)
    - devmate.addSelectedPathsAsReferences — Add multiple references/images from selected tree text

    Menus:
    - Editor context: Most chat actions (explain/refactor/optimize/etc.)
    - Explorer context: Add image/file content/file reference

    ### Working with Files and Images

    - Add File Content: Inserts file contents immediately as a code block.
    - Add File Reference: Inserts a lightweight reference; actual content is injected right before sending the next prompt. Toggle “Move reference to end” to auto‑pin near the query.
    - Inline file paths in responses: Any inline code that looks like a path becomes clickable and can be added automatically.
    - Images: Paste images into the prompt input or add via Explorer context menu. Images are attached as proper image parts.

    ### YAML Import/Export

    - Export: “Paste chat” inserts the current chat as YAML into the active editor. Collapsed states and moveToEnd flags are included.
    - Import (replace): Select YAML → “Use selection as DevMate AI Chat conversation”.
    - Import (append): Select YAML → “Append selection to DevMate AI Chat conversation”.

    YAML format is an array of messages with:
    ```yaml
    - role: user|assistant|system
      content: string | parts
      selected: true|false
      collapsed: true|false # optional
      moveToEnd: true|false # optional
    ```

    ### Streaming, Reasoning, and Stats

    - Output is streamed to the view.
    - Reasoning deltas are shown in a distinct color during streaming and are saved as a collapsed <think> assistant message after completion.
    - Token stats bar shows totals and per‑request usage.
    - Watchdog: If streaming stalls for ~90s, the partial output is finalized to avoid hanging.

    ### Keyboard Shortcuts

    - Enter: Send query (uses editor selection if configured).
    - Ctrl+Enter (Cmd+Enter on macOS): Send without querying the editor selection (Prompt No Query).

    ---

    ## Privacy & Security

    - DevMate sends your selected messages (including file contents, images, and references expanded at send time) to the configured provider endpoint(s). Review your content before sending.
    - Your API key is read from your VS Code settings (devmate.providers). Keep it secure.
    - DevMate does not transmit data anywhere else.

    ---

    ## Troubleshooting

    - “API key or API URL not set…”: Ensure devmate.providers is configured. Pick a provider/model in the UI.
    - Responses API errors:
      - Requires OpenAI SDK v6+ (Responses). Update dependencies and rebuild if needed.
    - Stalled stream:
      - The watchdog finalizes partial output after ~90s. Try again or check provider status.
    - Click‑to‑paste disabled:
      - Set devmate.pasteOnClick to true.

    ---

    ## Known Limitations

    - Token estimates use js‑tiktoken heuristics and may not match provider billing exactly.
    - Reasoning markers are visible in the stream but not saved in the final answer (saved separately in a collapsed <think> message).
    - Mixed lockfiles (npm/yarn) or SDK versions can cause mismatches (see Compatibility Notes).

    ---

    ## Roadmap

    - Multi‑message editing improvements
    - Model capability discovery in UI
    - More provider templates
    - Better diff/patch operations back to workspace

    ---

    ## Contributing

    Issues and PRs are welcome. Please:
    - Describe expected vs. actual behavior
    - Include logs (DevTools / Output) if relevant
    - For PRs, run lint/tests and keep changes focused

    ---

    ## Development Guide

    ### Project Structure

    ```
    .
    ├─ media/
    │  ├─ main.js               # Webview script (UI, streaming renderer, events, sanitization)
    │  ├─ styles.css            # Webview styles
    │  └─ scripts/              # Microlight, Tailwind, Showdown, DOMPurify
    ├─ src/
    │  ├─ extension.ts          # Activation, commands, configuration glue
    │  ├─ chatGptViewProvider.ts# Core chat logic, OpenAI calls, messages/state
    │  └─ types.ts              # Shared types, provider/model definitions
    ├─ dist/                    # Webpack output (extension.js)
    ├─ package.json
    ├─ package-lock.json / yarn.lock
    ├─ webpack.config.js
    ├─ tsconfig.json
    └─ vsc-extension-quickstart.md
    ```

    Architecture:
    - Extension host (Node): src/extension.ts, src/chatGptViewProvider.ts
    - UI (Webview): media/main.js + HTML generated by provider
    - Messaging: webview.postMessage / onDidReceiveMessage

    ### Build, Run, Test

    - Install deps:
      ```bash
      yarn
      # or: npm install
      ```
    - Build (bundle with webpack):
      ```bash
      yarn compile
      # or: npm run compile
      ```
    - Watch:
      ```bash
      yarn watch
      ```
    - Launch the extension:
      - Press F5 in VS Code (“Run Extension”)
    - Lint:
      ```bash
      yarn lint
      ```
    - Tests (Mocha):
      ```bash
      yarn test
      ```

    Note: The repo contains both package-lock.json and yarn.lock. Use one package manager consistently to avoid version drift. If using npm, you can refresh the lock with:
    ```bash
    npm run update-package-lock
    ```

    ### Packaging & Publishing (vsce)

    This project is packaged with vsce (Visual Studio Code Extension Manager).

    - Install vsce (globally):
      ```bash
      npm install -g @vscode/vsce
      ```
    - Build the bundle first:
      ```bash
      yarn compile
      # or: npm run compile
      ```
    - Create the .vsix package:
      ```bash
      vsce package
      ```
      This produces devmate-ai-chat-<version>.vsix in the project root.

    - Install the VSIX locally:
      ```bash
      code --install-extension devmate-ai-chat-*.vsix
      ```

    Notes:
    - vsce runs the vscode:prepublish script automatically if defined (this project’s prepublish bundles with webpack in production mode).
    - To publish to the Marketplace, follow:
      https://code.visualstudio.com/api/working-with-extensions/publishing-extension

    ### Webview Messaging Protocol

    Webview → Extension:
    - ready
    - prompt / promptNoQuery
    - pasteImage
    - codeSelected
    - checkboxChanged
    - messageContentChanged
    - collapseChanged
    - toggleMoveRefToEnd
    - providerModelChanged
    - systemPromptChanged
    - forceFinalizePartial
    - fileClicked

    Extension → Webview:
    - initialize (providers)
    - initialize_prompts (system prompts)
    - addResponse (render content)
    - updateResponse
    - clearResponse
    - setPrompt
    - updateStats (tokens/model)
    - resetCollapseState
    - setCollapsedForIndex
    - setMoveRefToEndForIndex
    - Streaming:
      - streamStart
      - appendDelta
      - appendReasoningDelta
      - streamEnd

    See media/main.js and src/chatGptViewProvider.ts for exact payload shapes.

    ### Providers & APIs

    - Model selection drives API usage:
      - chatCompletions: openai.chat.completions.create({ stream: true, ... })
      - responses: openai.responses.stream({ model, input, tools?, reasoning?, ... })
    - Tools (Responses API):
      - Server-side tools like web_search are handled by the provider.
      - Client-side custom tools are stubbed with a deterministic output so the model can proceed.
    - File references:
      - Lightweight string markers (e.g., <!--FILE:relative/path.ext-->) are expanded to code blocks at send time using the latest on-disk file contents.

    ### Compatibility Notes

    - OpenAI SDK:
      - This project targets OpenAI SDK v6+ for Responses API features. Ensure your installed version is ≥ 6 if you intend to use responses.stream().
      - If you see dependency mismatches (e.g., older openai versions in your lockfile), align by installing:
        ```bash
        npm install openai@^6
        # or
        yarn add openai@^6
        ```
    - Mixed lockfiles:
      - Prefer either npm or yarn. Remove the other lockfile to avoid version drift.

    ---

    ## Changelog

    - 1.1.0
      - Provider/Model selectors with Chat Completions & Responses support
      - Streaming with reasoning deltas and token stats bar
      - File references with “Move to end” toggle and path click handling
      - YAML import/export; Markdown selection import (with images)
      - Image paste support; inline editing; collapse/expand messages
      - Streaming watchdog for stalled responses

    ---

    ## License

    MIT © Diego Alfonso Aguilar Cardona
    ```
  selected: true
  collapsed: false
- role: user
  content: |-
    File reference: `media/main.js`
    <!--FILE:media/main.js-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `package-lock.json`
    <!--FILE:package-lock.json-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `package.json`
    <!--FILE:package.json-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `src/chatGptViewProvider.ts`
    <!--FILE:src/chatGptViewProvider.ts-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `src/extension.ts`
    <!--FILE:src/extension.ts-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `src/types.ts`
    <!--FILE:src/types.ts-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `tsconfig.json`
    <!--FILE:tsconfig.json-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `vsc-extension-quickstart.md`
    <!--FILE:vsc-extension-quickstart.md-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `webpack.config.js`
    <!--FILE:webpack.config.js-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: |-
    File reference: `yarn.lock`
    <!--FILE:yarn.lock-->
  selected: true
  collapsed: false
  moveToEnd: true
- role: user
  content: I want two modifications to the Readme. 1) I want the introduction to be more friendly, no so robotic, but also I want to explain why this is important.  The idea of this extension is that most of the assistants right now are more agentic, faster, but consumes too much and ends in endless loops of errors, here I give the control to the developer, he can define the context in each step of the process, I have been used this for more than 2 years in daily basis and it works perfect and my monthly consumtion in llms providers is about 10 usd, I don't have endless loops and it works perfect, I call it pseudo agentic development, and for now I know it works better than full agentic systems like Cline, Cursor, Antigravity, Claude Code, etc.  2) I want to give credit to the repo that I reference my project for.  I didn't do a fork, I just copied and started to modify it a lot, but I want to say that this project started as a fork of that project.
  selected: true
  collapsed: false
- role: assistant
  content: |-
    ```markdown
    # DevMate AI Chat

    DevMate is my “pseudo‑agentic” way to code with AI in VS Code. Instead of letting an autonomous agent spin up tools, hallucinate tasks, or loop on errors, you stay in control of the context at every step: choose which messages, files (content or references), images, and prompts to include and then send. I’ve used this workflow daily for 2+ years, it’s stable, avoids runaway loops, and keeps costs predictable (I average around $10/month across LLM providers). It complements faster, fully agentic IDEs (e.g., Cline, Cursor, Antigravity, Claude Code) but prioritizes reliability, determinism, and low burn. For many day‑to‑day tasks, this “pseudo‑agentic development” works better in practice.

    - Publisher: diegoaac
    - Extension ID: diegoaac.devmate-ai-chat
    - License: MIT
    - VS Code: ≥ 1.73.0

    ---

    ## Table of Contents

    - [Why DevMate (Pseudo‑Agentic)](#why-devmate-pseudoagentic)
    - [Features](#features)
    - [Requirements](#requirements)
    - [Installation](#installation)
    - [Quick Start](#quick-start)
    - [Configuration](#configuration)
      - [Providers (devmate.providers)](#providers-devmateproviders)
      - [System Prompts (devmate.prompts)](#system-prompts-devmateprompts)
      - [Behavior Settings](#behavior-settings)
    - [Usage](#usage)
      - [Chat View](#chat-view)
      - [Commands & Menus](#commands--menus)
      - [Working with Files and Images](#working-with-files-and-images)
      - [YAML Import/Export](#yaml-importexport)
      - [Streaming, Reasoning, and Stats](#streaming-reasoning-and-stats)
      - [Keyboard Shortcuts](#keyboard-shortcuts)
    - [Privacy & Security](#privacy--security)
    - [Troubleshooting](#troubleshooting)
    - [Known Limitations](#known-limitations)
    - [Roadmap](#roadmap)
    - [Contributing](#contributing)
    - [Development Guide](#development-guide)
      - [Project Structure](#project-structure)
      - [Build, Run, Test](#build-run-test)
      - [Packaging & Publishing (vsce)](#packaging--publishing-vsce)
      - [Webview Messaging Protocol](#webview-messaging-protocol)
      - [Providers & APIs](#providers--apis)
      - [Compatibility Notes](#compatibility-notes)
    - [Changelog](#changelog)
    - [Credits](#credits)
    - [License](#license)

    ---

    ## Why DevMate (Pseudo‑Agentic)

    - Stay in control: You decide the exact context per request (which prior messages, what file content vs. lightweight references, which images, which prompt).
    - Cut waste and loops: No endless tool runs or agent loops. Keep requests focused and auditable.
    - Predictable cost: Tight prompts and scoped context mean much lower token use; this has kept my monthly spend around ~$10.
    - Practical day‑to‑day: In many coding tasks, this hands‑on approach beats fully agentic systems for reliability and speed to “good enough.”

    ---

    ## Features

    - Provider/Model selectors per request
      - Chat Completions or Responses API (tools/reasoning) per model
    - Fast streaming output with optional “reasoning deltas”
    - Token stats: total, per‑request (prompt+completion), current model
    - Fine‑grained message controls
      - Include/Exclude from context
      - Collapse/Expand with preview
      - Inline edit
      - “Move file reference to end” toggle
    - Files and images
      - Add file content now, or lightweight references expanded on send
      - Clickable inline code paths open & add files
      - Paste/drag images or add from Explorer
    - YAML import/export for the whole chat
    - System Prompt selector
    - Click‑to‑paste code blocks into your editor (optional)
    - Watchdog to finalize stalled streams automatically

    ---

    ## Requirements

    - VS Code ≥ 1.73.0
    - An AI provider/API key (e.g., OpenAI-compatible)
    - Node.js for development/build
    - For Responses API features: OpenAI SDK v6+

    ---

    ## Installation

    - From VSIX:
      ```bash
      code --install-extension devmate-ai-chat-*.vsix
      ```
    - From Marketplace (when published): search “DevMate AI Chat”.

    Open Command Palette → “DevMate AI Chat: Ask DevMate AI Chat” or open the DevMate AI Chat view from the Activity Bar.

    ---

    ## Quick Start

    1. Open Settings and search “DevMate AI Chat”.
    2. Configure at least one provider in devmate.providers.
    3. Open the DevMate view (Activity Bar).
    4. Pick a provider/model and optional system prompt.
    5. Type your request and press Enter.

    ---

    ## Configuration

    All settings live under devmate.

    ### Providers (devmate.providers)

    ```json
    {
      "devmate.providers": [
        {
          "name": "OpenAI",
          "apiKey": "sk-...",
          "apiUrl": "https://api.openai.com/v1",
          "chatCompletionsUrl": "https://api.openai.com/v1",
          "responsesUrl": "https://api.openai.com/v1",
          "models": [
            {
              "name": "gpt-4o-mini (Chat Completions)",
              "model_name": "gpt-4o-mini",
              "api": "chatCompletions",
              "options": { "temperature": 0.7, "max_tokens": 1024 },
              "reasoning_output_delta_path": "choices[0].delta.reasoning"
            },
            {
              "name": "o4-mini (Responses)",
              "model_name": "o4-mini",
              "api": "responses",
              "tools": [{ "type": "web_search" }],
              "options": { "temperature": 0.6, "max_output_tokens": 2048, "reasoning": { "summary": "auto" } }
            }
          ]
        }
      ]
    }
    ```

    Notes:
    - Chat Completions uses chatCompletionsUrl (or apiUrl).
    - Responses uses responsesUrl (or apiUrl).
    - reasoning_output_delta_path is optional and provider‑specific.

    ### System Prompts (devmate.prompts)

    ```json
    {
      "devmate.prompts": [
        { "name": "Default", "prompt": "You are a helpful assistant." },
        { "name": "Explain-first", "prompt": "You are a meticulous assistant. First explain the reasoning, then provide the code." }
      ]
    }
    ```

    ### Behavior Settings

    ```json
    {
      "devmate.pasteOnClick": true,
      "devmate.selectedInsideCodeblock": true,
      "devmate.codeblockWithLanguageId": true,
      "devmate.keepConversation": true,
      "devmate.timeoutLength": 120
    }
    ```

    ---

    ## Usage

    ### Chat View

    - Top: Provider/Model selectors
    - Middle: Messages (include/exclude, collapse/expand, inline edit, “move ref to end” on reference messages)
    - Bottom: System Prompt selector + input
    - Stats bar shows tokens and current model

    ### Commands & Menus

    - devmate.ask — Ask DevMate AI Chat
    - devmate.explain — Explain selection
    - devmate.refactor — Refactor selection
    - devmate.optimize — Optimize selection
    - devmate.findProblems — Find problems
    - devmate.documentation — Write documentation
    - devmate.resetConversation — Reset conversation
    - devmate.pasteChat — Paste chat (export YAML)
    - devmate.useSelectionAsChat — Replace chat from selected YAML
    - devmate.appendSelectionAsChat — Append selected YAML
    - devmate.appendSelectionMarkdownAsChat — Append Markdown (text+images)
    - devmate.addImageToChat — Add image (Explorer)
    - devmate.addFileToChat — Add file content (Explorer)
    - devmate.addFileReferenceToChat — Add file reference (Explorer)
    - devmate.addSelectedPathsAsReferences — Add multiple references/images from a selected “tree” text

    ### Working with Files and Images

    - File Content: embeds the file as a code block now.
    - File Reference: adds a lightweight reference and expands on send. Optionally “move to end” so it sits next to your latest query.
    - Inline code paths in answers are clickable and can be added automatically.
    - Images: paste/drag into input or add via Explorer.

    ### YAML Import/Export

    - Export: “Paste chat” inserts YAML into your editor, including collapsed/moveToEnd flags.
    - Import: Replace or append from selected YAML.

    YAML shape:
    ```yaml
    - role: user|assistant|system
      content: string | parts
      selected: true|false
      collapsed: true|false # optional
      moveToEnd: true|false # optional
    ```

    ### Streaming, Reasoning, and Stats

    - Output streams live; optional reasoning deltas display in a distinct style and are saved as a collapsed <think> message.
    - Watchdog finalizes if the stream stalls (~90s).

    ### Keyboard Shortcuts

    - Enter: Send
    - Ctrl+Enter (Cmd+Enter): Send (No Query)

    ---

    ## Privacy & Security

    - Only the content you select (messages/files/images) is sent to your configured provider endpoint(s).
    - API keys are read from your VS Code settings.
    - No other telemetry or data exfiltration.

    ---

    ## Troubleshooting

    - “API key or API URL not set…” → Configure devmate.providers and pick a model.
    - Responses API not available → Use OpenAI SDK v6+ and rebuild.
    - Stalled stream → Watchdog will finalize; retry or check provider status.
    - Click‑to‑paste not working → Enable devmate.pasteOnClick.

    ---

    ## Known Limitations

    - Token stats are estimates and may not match billing exactly.
    - Reasoning deltas are streamed separately and saved as a collapsed <think> message.
    - Mixed npm/yarn lockfiles can cause dependency drift (see Compatibility Notes).

    ---

    ## Roadmap

    - Better multi‑message editing
    - Provider templates and capability discovery
    - Smarter diffs/patches back to files

    ---

    ## Contributing

    Issues and PRs are welcome. Please include repro steps and logs if relevant, and keep PRs focused.

    ---

    ## Development Guide

    ### Project Structure

    ```
    .
    ├─ media/
    │  ├─ main.js               # Webview UI + streaming renderer
    │  ├─ styles.css
    │  └─ scripts/              # Microlight, Tailwind, Showdown, DOMPurify
    ├─ src/
    │  ├─ extension.ts          # Activation, commands, settings
    │  ├─ chatGptViewProvider.ts# Chat logic, OpenAI calls, state
    │  └─ types.ts              # Shared types
    ├─ dist/                    # Webpack output
    ├─ package.json
    ├─ package-lock.json / yarn.lock
    ├─ webpack.config.js
    ├─ tsconfig.json
    └─ vsc-extension-quickstart.md
    ```

    ### Build, Run, Test

    ```bash
    # install deps
    yarn        # or: npm install

    # dev build
    yarn compile    # or: npm run compile
    yarn watch

    # run the extension
    # Press F5 in VS Code (“Run Extension”)

    # lint / test
    yarn lint
    yarn test
    ```

    Note: The repo contains both package-lock.json and yarn.lock. Use one package manager consistently. If using npm:
    ```bash
    npm run update-package-lock
    ```

    ### Packaging & Publishing (vsce)

    This project uses vsce to create the .vsix.

    ```bash
    npm install -g @vscode/vsce

    # production bundle (prepublish)
    yarn compile   # or: npm run compile

    # create VSIX
    vsce package

    # install locally
    code --install-extension devmate-ai-chat-*.vsix
    ```

    vsce runs the vscode:prepublish script automatically if defined.

    ### Webview Messaging Protocol

    Webview → Extension:
    - ready
    - prompt / promptNoQuery
    - pasteImage
    - codeSelected
    - checkboxChanged
    - messageContentChanged
    - collapseChanged
    - toggleMoveRefToEnd
    - providerModelChanged
    - systemPromptChanged
    - forceFinalizePartial
    - fileClicked

    Extension → Webview:
    - initialize (providers)
    - initialize_prompts (system prompts)
    - addResponse / updateResponse / clearResponse
    - setPrompt
    - updateStats
    - resetCollapseState
    - setCollapsedForIndex
    - setMoveRefToEndForIndex
    - streamStart / appendDelta / appendReasoningDelta / streamEnd

    ### Providers & APIs

    - Chat Completions: openai.chat.completions.create({ stream: true, ... })
    - Responses: openai.responses.stream({ model, input, tools?, reasoning?, ... })
    - Tools: Server‑side tools (e.g., web_search) are handled by the provider. Client‑side custom tools are stubbed so the model can proceed.
    - File references: Lightweight markers (e.g., <!--FILE:relative/path.ext-->) expand on send to current file contents.

    ### Compatibility Notes

    - OpenAI SDK v6+ recommended for Responses API support:
      ```bash
      npm install openai@^6
      # or
      yarn add openai@^6
      ```
    - If lockfiles pull older versions, align and rebuild.

    ---

    ## Changelog

    - 1.1.0
      - Provider/Model selectors (Chat Completions & Responses)
      - Streaming + reasoning deltas + token stats
      - File references with “move to end” + clickable path handling
      - YAML import/export; Markdown selection import
      - Image paste; inline editing; collapse/expand; stream watchdog

    ---

    ## Credits

    This project started as a fork of the following repository. Huge thanks to the original author(s) for the groundwork:
    - Original project: REPLACE_WITH_ORIGINAL_REPO_NAME (REPLACE_WITH_ORIGINAL_REPO_URL)

    If you were involved in the original project and want specific attribution, please open an issue or PR.

    ---

    ## License

    MIT © Diego Alfonso Aguilar Cardona
    ```
  selected: true
  collapsed: false
